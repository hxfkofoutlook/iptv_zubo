#!/usr/bin/env python3
"""
IPTVæºæ£€æµ‹è„šæœ¬ - æ ¹æ®çµæ´»åŒ¹é…è§„åˆ™ä»GitHubæ”¶é›†å¹¶æµ‹è¯•IP
"""

import os
import re
import json
import time
import requests
import concurrent.futures
from datetime import datetime
from collections import defaultdict
from typing import Dict, List, Set, Optional

# ===============================
# é…ç½®åŒº
# ===============================

# ç›®æ ‡çœä»½è¿è¥å•†ä¸ç»„æ’­åœ°å€æ˜ å°„
TARGETS = [
    ("åŒ—äº¬", "ç§»åŠ¨", "228.1.1.128:8001"),
    ("åŒ—äº¬", "è”é€š", "239.3.1.238:8001"),
    ("åŒ—äº¬", "ç”µä¿¡", "225.1.8.36:8002"),
    ("æ¹–å—", "ç”µä¿¡", "239.76.253.100:9000"),
    ("ä¸Šæµ·", "ç”µä¿¡", "233.18.204.51:5140"),
    ("å¹¿ä¸œ", "ç”µä¿¡", "239.77.0.112:5146"),
    ("æµ·å—", "ç”µä¿¡", "239.253.64.14:5140"),
    ("å››å·", "ç”µä¿¡", "239.94.0.60:5140"),
    ("é‡åº†", "ç”µä¿¡", "235.254.197.237:7980"),
    ("æ²³åŒ—", "è”é€š", "239.253.92.154:6011"),
    ("æ²³åŒ—", "ç”µä¿¡", "239.254.200.174:6000"),
]

# GitHubä»“åº“åˆ—è¡¨
REPOS = [
    "kakaxi-1/zubo",
    "IPTV520/zubo",
    "a52948/zubo",
    "AimerJansen/zubo",
    "caliph21/zubo",
    "cgj555/zubo",
    "Francis-228/zubo",
    "gclgg/zubo",
]

# æµ‹è¯•é…ç½®
REQUEST_TIMEOUT = 10
TEST_TIMEOUT = 8
MAX_WORKERS = 15
MAX_IPS_PER_TARGET = 100  # æ¯ä¸ªç›®æ ‡æœ€å¤šæµ‹è¯•çš„IPæ•°é‡
OUTPUT_FILE = "iptv.json"

# ===============================
# è¾…åŠ©å‡½æ•°
# ===============================

def fetch_repo_files(repo: str) -> Optional[List[Dict]]:
    """è·å–ä»“åº“ipç›®å½•ä¸‹çš„æ–‡ä»¶åˆ—è¡¨"""
    api_url = f"https://api.github.com/repos/{repo}/contents/ip"
    headers = {'User-Agent': 'IPTV-Scanner'}
    
    # ä½¿ç”¨GitHub Tokené¿å…é€Ÿç‡é™åˆ¶
    if 'GITHUB_TOKEN' in os.environ:
        headers['Authorization'] = f"token {os.environ['GITHUB_TOKEN']}"
    
    try:
        resp = requests.get(api_url, headers=headers, timeout=REQUEST_TIMEOUT)
        if resp.status_code == 200:
            return resp.json()
        elif resp.status_code == 403:
            print(f"  è­¦å‘Š: {repo} è®¿é—®è¢«é™åˆ¶")
        else:
            print(f"  è­¦å‘Š: {repo} è¿”å›çŠ¶æ€ç  {resp.status_code}")
    except Exception as e:
        print(f"  é”™è¯¯: è·å– {repo} å¤±è´¥: {e}")
    
    return None

def is_target_match(filename: str, province: str, isp: str) -> bool:
    """
    æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ¹é…ç›®æ ‡çœä»½å’Œè¿è¥å•†
    è§„åˆ™: åªè¦åŒæ—¶åŒ…å«çœä»½å…³é”®è¯å’Œè¿è¥å•†å…³é”®è¯å°±åŒ¹é…
    """
    # ç§»é™¤æ–‡ä»¶æ‰©å±•åå’Œç©ºæ ¼
    name = filename.replace('.txt', '').replace(' ', '')
    
    # æ£€æŸ¥æ˜¯å¦åŒæ—¶åŒ…å«çœä»½å’Œè¿è¥å•†
    # æ³¨æ„: çœä»½å…³é”®è¯åªéœ€åŒ¹é…ä¸¤ä¸ªå­—ï¼Œæ¯”å¦‚"åŒ—äº¬"åŒ¹é…"åŒ—äº¬å¸‚"
    # è¿è¥å•†å…³é”®è¯éœ€è¦å®Œå…¨åŒ¹é…
    province_in_name = province in name
    isp_in_name = isp in name
    
    return province_in_name and isp_in_name

def extract_ips_from_url(download_url: str) -> Set[str]:
    """ä»ä¸‹è½½é“¾æ¥æå–IP:ç«¯å£"""
    ips = set()
    try:
        resp = requests.get(download_url, timeout=REQUEST_TIMEOUT)
        if resp.status_code == 200:
            # åŒ¹é…IP:ç«¯å£æ ¼å¼
            lines = resp.text.split('\n')
            for line in lines:
                line = line.strip()
                if line and not line.startswith('#'):
                    # ç®€å•éªŒè¯IP:ç«¯å£æ ¼å¼
                    if re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d+$', line):
                        ips.add(line)
    except Exception as e:
        print(f"    ä¸‹è½½å¤±è´¥: {e}")
    
    return ips

def test_ip_speed(ip_port: str, multicast_addr: str) -> Optional[Dict]:
    """
    æµ‹è¯•å•ä¸ªIPçš„å¯ç”¨æ€§å’Œé€Ÿåº¦
    è¿”å›åŒ…å«é€Ÿåº¦ä¿¡æ¯çš„ç»“æœå­—å…¸
    """
    test_url = f"http://{ip_port}/rtp/{multicast_addr}"
    
    try:
        # ç¬¬ä¸€é˜¶æ®µ: å¿«é€ŸHEADè¯·æ±‚æ£€æŸ¥åŸºæœ¬è¿é€šæ€§
        start_time = time.time()
        head_resp = requests.head(
            test_url,
            timeout=3,
            allow_redirects=True
        )
        latency = time.time() - start_time
        
        if head_resp.status_code >= 400:
            return None
        
        # ç¬¬äºŒé˜¶æ®µ: ä¸‹è½½ä¸€å°æ®µæ•°æ®æµ‹è¯•é€Ÿåº¦
        chunk_size = 1024 * 8  # 8KB
        speed_start = time.time()
        
        with requests.get(
            test_url,
            stream=True,
            timeout=TEST_TIMEOUT
        ) as resp:
            if resp.status_code >= 400:
                return None
            
            # è¯»å–æ•°æ®ç›´åˆ°è¾¾åˆ°32KBæˆ–è¶…æ—¶
            total_bytes = 0
            max_bytes = 1024 * 32  # 32KB
            time_limit = 5  # 5ç§’é™åˆ¶
            
            for chunk in resp.iter_content(chunk_size=chunk_size):
                if not chunk:
                    break
                    
                total_bytes += len(chunk)
                if total_bytes >= max_bytes or (time.time() - speed_start) > time_limit:
                    break
        
        download_time = time.time() - speed_start
        
        if download_time == 0:
            return None
        
        # è®¡ç®—é€Ÿåº¦ (KB/s)
        speed_kbps = (total_bytes / 1024) / download_time
        
        # è®¡ç®—ç»¼åˆè¯„åˆ† (é€Ÿåº¦/å»¶è¿Ÿ)
        score = speed_kbps / max(latency, 0.001)
        
        return {
            'url': test_url,
            'ip_port': ip_port,
            'speed_kbps': round(speed_kbps, 2),
            'latency_ms': round(latency * 1000, 2),
            'score': round(score, 2)
        }
        
    except Exception:
        return None

def batch_test_ips(ip_list: List[str], multicast_addr: str) -> List[Dict]:
    """æ‰¹é‡æµ‹è¯•IPåˆ—è¡¨"""
    results = []
    
    # é™åˆ¶æµ‹è¯•æ•°é‡é¿å…è€—æ—¶è¿‡é•¿
    test_ips = ip_list[:MAX_IPS_PER_TARGET]
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_ip = {
            executor.submit(test_ip_speed, ip, multicast_addr): ip 
            for ip in test_ips
        }
        
        for future in concurrent.futures.as_completed(future_to_ip):
            result = future.result()
            if result:
                results.append(result)
    
    return results

def main():
    print("ğŸš€ IPTVæºæ£€æµ‹æµç¨‹å¼€å§‹")
    print("=" * 60)
    
    # æ­¥éª¤1: ä»æ‰€æœ‰ä»“åº“æ”¶é›†IP
    print("ğŸ“¦ ä»GitHubä»“åº“æ”¶é›†IPæ–‡ä»¶ä¸­...")
    
    # æ•°æ®ç»“æ„: {(çœä»½, è¿è¥å•†): {ip1, ip2...}}
    ip_collections = defaultdict(set)
    
    for repo in REPOS:
        print(f"\nå¤„ç†ä»“åº“: {repo}")
        files = fetch_repo_files(repo)
        
        if not files:
            continue
        
        # ç­›é€‰å‡º.txtæ–‡ä»¶
        txt_files = [f for f in files if f['type'] == 'file' and f['name'].endswith('.txt')]
        
        for file_info in txt_files:
            filename = file_info['name']
            
            # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•ç›®æ ‡
            for province, isp, _ in TARGETS:
                if is_target_match(filename, province, isp):
                    print(f"  âœ… åŒ¹é…åˆ°: {filename} -> {province}{isp}")
                    
                    # ä¸‹è½½å¹¶æå–IP
                    ips = extract_ips_from_url(file_info['download_url'])
                    if ips:
                        key = (province, isp)
                        ip_collections[key].update(ips)
                        print(f"    æå–åˆ° {len(ips)} ä¸ªIP")
                    break
    
    print(f"\nâœ… IPæ”¶é›†å®Œæˆ")
    print(f"   æ‰¾åˆ° {len(ip_collections)} ä¸ªç›®æ ‡ç»„åˆ")
    
    # æ˜¾ç¤ºæ¯ä¸ªç»„åˆæ”¶é›†åˆ°çš„IPæ•°é‡
    for (province, isp), ips in ip_collections.items():
        print(f"   {province}{isp}: {len(ips)} ä¸ªIP")
    
    # æ­¥éª¤2: å¯¹æ¯ä¸ªç»„åˆè¿›è¡ŒIPæµ‹è¯•å’Œç­›é€‰
    print("\nğŸ§ª å¼€å§‹IPè¿é€šæ€§å’Œé€Ÿåº¦æµ‹è¯•...")
    final_results = {}
    
    for (province, isp), ip_set in ip_collections.items():
        # è·å–å¯¹åº”çš„ç»„æ’­åœ°å€
        multicast = next((addr for p, i, addr in TARGETS if p == province and i == isp), None)
        if not multicast:
            print(f"  è­¦å‘Š: æœªæ‰¾åˆ° {province}{isp} çš„ç»„æ’­åœ°å€ï¼Œè·³è¿‡")
            continue
        
        ip_list = list(ip_set)
        print(f"\n  æµ‹è¯• {province}{isp}: {len(ip_list)}ä¸ªIP")
        
        if not ip_list:
            continue
        
        # æ‰¹é‡æµ‹è¯•IP
        test_results = batch_test_ips(ip_list, multicast)
        
        if test_results:
            # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
            test_results.sort(key=lambda x: x['score'], reverse=True)
            
            # å–æœ€å¿«çš„2ä¸ª
            top_results = test_results[:2]
            
            # æ ¼å¼åŒ–ç»“æœ
            final_results[f"{province}{isp}"] = [
                {
                    "url": item['url'],
                    "speed_kbps": item['speed_kbps'],
                    "latency_ms": item['latency_ms']
                }
                for item in top_results
            ]
            
            print(f"    âœ… æ‰¾åˆ° {len(top_results)} ä¸ªé«˜é€Ÿæº")
            for i, item in enumerate(top_results, 1):
                print(f"      ç¬¬{i}å: {item['speed_kbps']} KB/s, å»¶è¿Ÿ: {item['latency_ms']}ms")
        else:
            print(f"    âŒ æ²¡æœ‰å¯ç”¨çš„IP")
    
    # æ­¥éª¤3: ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
    output_data = {
        "update_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "update_timestamp": int(time.time()),
        "total_sources": len(final_results),
        "total_streams": sum(len(streams) for streams in final_results.values()),
        "sources": final_results
    }
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 60)
    print(f"ğŸ‰ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ° {OUTPUT_FILE}")
    print(f"   è¦†ç›–ç»„åˆ: {output_data['total_sources']} ä¸ª")
    print(f"   æ€»æµæ•°é‡: {output_data['total_streams']} ä¸ª")
    print(f"   æ›´æ–°æ—¶é—´: {output_data['update_time']}")
    print("=" * 60)

if __name__ == "__main__":
    main()
